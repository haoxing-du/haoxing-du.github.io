---
title:  Is the quantum state a state of knowledge?
date: 2022-05-25
tags: ["psi-epistemic"]
mathjax: true
---

## A category mistake

On the early morning of September 14, 1822, a young Frenchman named Jean-Francois Champollion was running through the streets of Paris. He burst into his brother's office at the Académie des Inscriptions, and shouted, "*Je tiens mon affaire!*" ("I've done it!"), before collapsing on the floor. Champollion had just become the first person able to read ancient Egyptian hieroglyphs in two thousand years. 

Following the sleepless nights that led to this historic achievement, Champollion would immediately succumb to a week-long, exhaustion-induced illness, and the decipherment of Egyptian hieroglyphs would go down in history as one of the best examples that demonstrate how simple, incorrect assumptions can drastically hinder scientific progress. In this particular case, the roadblock amounted to one simple assumption about the nature of the hieroglyphs, what *type* of objects they are---a category mistake. For generations, scholars studying the script believed that the hieroglyphs are *ideographic*, meaning that they are symbols that represent ideas. However, as Champollion had eventually figured out, this was a false premise. Much of the Egyptian hieroglyphic script is in fact *phonetic*, with symbols representing sounds.

How did the belief that the hieroglyphs were ideographic come into being in the first place? Efforts to decipher Egyptian hieroglyphs started not long after the Ancient Egyptian scripts ceased to be understood in the fourth century BC. Rather unfortunately, pretty much all scholars who worked on the decipherment had assumed that the hieroglyphs are ideographic from the get go, perhaps due to their extremely visually suggestive nature. The result of such an assumption was a stall in progress for essentially a millennium. No matter how hard people tried, they could not figure out what ideas corresponded to which symbols. And this was not due to a lack of imagination. In his treatise on the subject, [*Hieroglyphica*](https://www.google.com/books/edition/Hieroglyphics_of_Horapollo_Nilous/9boHVUTq_vEC?hl=en&gbpv=0), Ancient Greek scholar Horapollo showcased his extraordinary imagination with his theory on the meaning of 189 hieroglyphs. For example, let's take a look at these three symbols:

<center>
<img src="/images/psi-epi/goose.png" alt="goose" width="100"/>
<img src="/images/psi-epi/ibis.png" alt="ibis" width="100"/>
<img src="/images/psi-epi/swallow.png" alt="swallow" width="100"/>
</center>

According to Horapollo, the first of these hieroglyphs means "son", represented as a goose. This is because---reasons Horapollo---the goose is excessively fond of its offspring, and routinely sacrifice their own lives to preserve those of its young. The second bird is an ibis, and according to Horapollo means "heart", both because it resembles the shape of a heart and that the ibis is "consecrated to Hermes [Thoth], the lord of every heart and of reasoning". The third bird is a swallow, and represents "the whole of a parent's substance has been left to the sons". This is because "[a swallow] rolls herself in the mud, and builds a nest for her young, when she is herself about to die".

Now, the first of these interpretations is actually known to be correct---Horapollo lived fairly close in time to people who knew the hieroglyphs, and it looks like some genuine knowledge about the script was retained. But it is not for the reasons that Horapollo thought. Instead, the goose symbol represents the syllable "sꜣ", which is the pronunciation of the word for "son" in the spoken language of Ancient Egyptians. [^determinative] Needless to say, most of his interpretation are now proven to be complete nonsense. Nevertheless, the harm was done. Even though some of these interpretations are so wildly speculative that they probably were never taken as true, scholars pursuing the decipherment of the hieroglyphs following Horapollo's footsteps internalized the premise that the hieroglyphs are ideographic.

[^determinative]: It turns out that even the little rectangular box is relevant. It is a vertical stroke that denotes a "determinative", which serves to distinguish it from other words that are pronounced "sꜣ".

As a result, it was not until the discovery of the Rosetta Stone that real progress started being made. The Rosetta Stone, discovered by Napoleon’s army in 1799, bears the exact same passage of text in three different scripts: hieroglyphs on top, Ancient Greek at the bottom, and an unidentified script (later to be deemed Demotic, a different type of Ancient Egyptian script) in the middle. Since Ancient Greek was still a known language, this enabled a direct side-by-side comparison of the languages. It’s basically as close as we could hope to get to a dictionary. 

Even then, the hieroglyphs were not deciphered right away. Soon after the discovery of the Stone, scholars such as Thomas Young had correctly figured out that the parts of the text that were enclosed in little ovals, named “cartouches”, correspond to names of Egyptian kings. Building upon the work of Young and others, our hero Champollion was able to deduce that the cartouches below spelled the names "Ptolemy" and "Cleopatra", and he was able to identify the phonetic values of some hieroglyphs by comparing the two names.

<center>
<img src="/images/psi-epi/ptolemy.jpeg" alt="ptolemy" width="300"/>
<img src="/images/psi-epi/cleopatra.jpeg" alt="cleopatra" width="500"/>
<img src="/images/psi-epi/phonetic.jpeg" alt="phonetic" width="500"/>
</center>

However, even then, Champollion did not go on and decipher the rest of the script right away. The idea that the hieroglyphs were ideographic was so entrenched in his mind that he thought only names of foreign origin were spelled out phonetically, as were Ptolemy and Cleopatra. It was not after many more months of effort without progress did Champollion finally start to entertain the idea that perhaps hieroglyphs can be phonetic outside of cartouches. As soon as he started looking at the text with this new assumption, he immediately started to recognize familiar phonetic elements from a language that was still in use and that he was familiar with, Coptic. [^coptic] This was it. It turns out that the Egyptian hieroglyphs are essentially another alphabet for the spoken language of Coptic, and Champollion would land on the floor of his brother’s office a few days later. [^story]

[^coptic]: This is somewhat of a lucky coincidence, actually. By the 19th century, [Coptic](https://en.wikipedia.org/wiki/Coptic_language) was no longer in use other than as the liturgical language of the Coptic Church. Champollion had studied Coptic because of his fascination with ancient Egypt and the connection of Coptic to various ancient Egyptian languages.

[^story]: This was, of course, a dramaticized version of the story of how the hieroglyphs were deciphered. The whole script was definitely not deciphered by Champollion alone in one day, and involved a lot more effort by many people for many more years. For a more detailed account of the decipherment of the Egyptian hieroglyphs, see this [Wikipedia](https://en.wikipedia.org/wiki/Decipherment_of_ancient_Egyptian_scripts) page.



##  $\psi$-onticity: another category mistake?

I love the story of the decipherment of the hieroglyphs, and what it teaches us about how bafflingly costly a category mistake can be. Of course, I’d better start talking about the foundations of quantum theory before you start wondering what happened to this blog and stop reading. The reason why I’m bringing up the tale of deciphering hieroglyphs---besides that I really love good stories---is because I want to ask the following question: **Could the reason why we have been stuck on the interpretation of quantum theory be that we are making a similar category mistake?** By assuming that the hieroglyphs are ideograms, scholars were stumped for a millennium, while the spoken language of Coptic was being passed on from generation to generation. What could be a possible incorrect assumption that we have been making in the interpretation of quantum theory?

Before I discuss the candidate assumption that I have in mind, I need to first define a very important distinction: ontic versus epistemic. Loosely speaking, something is *ontic* if it is real, or corresponds to an element of reality, and something is *epistemic* if it corresponds to the knowledge possessed by some agent. While this is by no means a clear distinction, and it can sometimes be tricky to judge whether something is ontic or epistemic, a simple puzzle comes in handy to illustrate this distinction:


You move to a new town to start a new job. On your new daily commute, you drive by this billboard every day, but unfortunately the display seems to be broken. How would you go about figuring out what the billboard is supposed to say?

<center>
<img src="/images/psi-epi/billboard.jpeg" alt="billboard" width="450"/>
</center>

The numbers on the billboard change every day, so you suspect that the numbers have to do with weather. Enjoying a little challenge, you decide to conduct your own experiments to figure out the meaning of the numbers. You go and buy a thermometer (or use a clever contraption of your own device, if you prefer), and see that the highest temperature of the whole day is 18 degrees Celsius when the first entry on the billboard says 18. Aha! Similarly, you measure the wind speed, and realize that the second entry says 19 when the wind speed, averaged over the whole day, is about 19 kilometers per hour. The third one takes you a bit longer to figure out. Eventually you decide to take a bunch of pictures of the local sky, and you find that the billboard says 35% when 35% of the sky is covered by clouds on average. [^cloud] You are a bit stumped by the fourth one, though. You keep measuring more and more weather-related quantities, but you can't seem to find anything that is 40% when the billboard says 40%.

[^cloud]: "Average cloud cover" is a field reported by the weather app that I use. I didn't know it is a thing either!

Eventually, after many weeks of effort, (thankfully, everything takes forever to fix so you get to continue carrying out your investigation), you sit down to tally up all the data you have collected so far. You realize that out of all the days that the billboard said 40% for the last entry, it rained on about 40% of them! Similarly, out of all the days that the billboard said 80%, it rained about 80% of the time, and so on. You have now solved the puzzle: the last number on the billboard is the probability of rain.

In this little puzzle, the first three quantities reported on the billboard are _ontic_, and you were able to figure out what they corresponded to by measuring aspects of the weather (i.e. elements of reality). The probability of rain was much harder for you to figure out, because it is an _epistemic_ quantity---something of a completely different nature. It is the weather forecaster's belief (perhaps an unrealistically accurate one) about the weather. There is nothing in the real world that is 40% when the probability of rain is reported as 40%.

With this distinction between ontic and epistemic things, we are now ready to ask: is the quantum state ontic or epistemic? We will call a theory in which quantum states are states of reality $\psi$-ontic, and one in which quantum states are states of knowledge $\psi$-epistemic.

Among the existing interpretations of quantum theory, it sure looks like the $\psi$-ontic view is dominant. In fact, a number of interpretations take the $\psi$-*complete* position, which is that the quantum state alone is a complete description of reality. Interpretations taking this position include the [many worlds interpretation](https://plato.stanford.edu/entries/qm-manyworlds/), which is the subject of my last [blog post](http://www.haoxingdu.com/post/mw/). Perhaps more prominently, this is also the position endorsed by the "orthodox" interpretation that is presented in many textbooks on quantum mechanics. Some textbooks straight up teach it as an axiom of quantum mechanics, such as John Preskill's [lecture notes](http://theory.caltech.edu/~preskill/ph219/chap2_15.pdf) on quantum information:
> **Axiom 1. States.** A state is a complete description of a physical system. In quantum mechanics, a state is a ray in a Hilbert space. 

$\psi$-onticity is a weaker notion than $\psi$-completeness. Hidden variable theories, which posit additional variables that make up the description of reality, often give the quantum state an ontic status. One prominent example of this type of theories is [Bohmian mechanics](https://plato.stanford.edu/entries/qm-bohm/). In Bohmian mechanics, the ontology is posited to be the quantum state, together with some additional variables that are the positions of the particles. Most other ontological models for quantum theory that have been studied to date also regard the quantum state as ontic.

[^comment]: At face value, this does not seem to tell us whether the quantum state is ontic or epistemic. However, with one extra logical step, we see that this means that the quantum state must be ontic: if the quantum state were epistemic, then it must be possible for two different quantum states to describe the same state of reality. But if the quantum state is a "complete description of a physical system", then different quantum states must correspond to different realities.

Given this, it might appear that the ontic status of the quantum state is the overwhelming consensus, and the answer to our question is clear. But is there really any evidence that the quantum state is ontic? Could $\psi$-onticity be just like the plausible but ultimately incorrect assumption that the Egyptian hieroglyphs are ideographic? Below, I argue that $\psi$-onticity might be a problematic premise that has been widely internalized without good reasons. I will make this case from two angles: first, why $\psi$-onticity is problematic from the standpoint of locality, and second, why there appears to be strong evidence for the epistemic nature of the quantum state.

## Locality

By locality here, I mean the idea that a system can only be influenced by events in its past lightcone. [^locality] The tension between $\psi$-onticity and locality is not at all subtle, and arguments pointing out this conflict have a long history. Einstein was perhaps the first and most prominent figure to make this point. It is well-known that Einstein was troubled by the $\psi$-complete position, and that he had attempted to construct a hidden variable model of his own. [This article](https://arxiv.org/abs/0706.2661) analyzes various arguments by Einstein, and argues that he not only argued against $\psi$-completeness, but in fact favored a $\psi$-epistemic interpretation.

[^locality]: More precisely, what I described here is the concept of *local causality*. Locality sometimes encompasses both local causality and a different concept called *separability*, which is the idea that the complete description of an overall system is simply the combination of descriptions of its constituents. Note that the $\psi$-complete view already violates separability, since by the axioms of quantum theory, we know that quantum states are combined via tensor products, not Cartesian products.

Without getting into the historical details, I will present here the simplest way to see the tension between $\psi$-onticity and locality---through the phenomenon of steering. Suppose that Alice and Bob shared a pair of qubits (say, the spin of some particle) in the maximally entangled state, $$\ket{\psi^-} = \frac{\ket{\uparrow}\ket{\downarrow} - \ket{\downarrow}\ket{\uparrow}}{\sqrt{2}}.$$ 
This state is called the *singlet*, and it has the property that no matter what direction Alice and Bob choose to measure their spins in, they are guaranteed to find them in opposite directions.

In a bit more detail, it works like this: If Alice measures her qubit in the {$\ket{\uparrow}, \ket{\downarrow}$} basis, quantum theory predicts that she would get outcome $\uparrow$ and $\downarrow$ with 50-50 probability. If she gets outcome $\uparrow$, then the quantum state of her qubit is immediately updated (or collapsed) to $\ket{\uparrow}$, and the quantum state of Bob's qubit is immediately updated to $\ket{\downarrow}$. This means that Bob is guaranteed to get outcome $\downarrow$ if and when he measures his qubit in the $\{ \ket{\uparrow}, \ket{\downarrow} \}$ basis as well. Suppose that Alice instead chooses to measure her qubit in another basis, say, the basis {$\ket{+\hat{n}}, \ket{-\hat{n}}$}, where $\ket{+\hat{n}}$ points angle $\theta$ away from the $\uparrow$ direction, and $\ket{-\hat{n}}$ points the opposite direction from $\ket{+\hat{n}}$. Since the singlet can be equivalently rewritten as $$\ket{\psi^-} = \frac{\ket{+\hat{n}}\ket{-\hat{n}} - \ket{-\hat{n}}\ket{+\hat{n}}}{\sqrt{2}},$$ she would still get outcome $+\hat{n}$ and $-\hat{n}$ with 50-50 odds. And if she got outcome $+\hat{n}$, that would update the quantum state of her qubit to $\ket{+\hat{n}}$, and that of Bob's qubit to $\ket{-\hat{n}}$, guaranteeing that he gets the $-\hat{n}$ outcome when measuring his qubit in the same basis. This way, Alice and Bob would always find their spins in opposite directions.

To bring locality into the picture, now note that the above analysis holds no matter how far apart Alice and Bob are separated. Quantum theory predicts that Alice's measurement on her qubit *instantaneously* changes the state of Bob's qubit, even when they are on opposite sides of the galaxy. In particular, by choosing to measure her qubit in the {$\ket{\uparrow}, \ket{\downarrow}$} basis, Alice can make Bob's qubit to be in either state $\ket{\uparrow}$ or state $\ket{\downarrow}$, whereas by measuring her qubit in the {$\ket{+\hat{n}}, \ket{-\hat{n}}$} basis, she makes Bob's qubit be in one of $\ket{+\hat{n}}$ and $\ket{-\hat{n}}$ instead. This is already very problematic if one believes that the quantum state is a state of reality---this means that Alice's action can instantaneously influence the reality lightyears away. This phenomenon is precisely what Einstein termed "spooky action at a distance" [^saad].

[^saad]: Note that the usual analysis in a quantum mechanics textbook points out that despite the instantaneous update, Alice and Bob cannot use this to send each other information instantaneously. This is true, but is besides the point. The failure to communicate does not absolve $\psi$-onticity of implying superluminal influences.

If one takes the perspective that quantum states are states of knowledge, i.e. are epistemic, however, then they would not find the steering phenomenon troubling at all. The instantaneous update on the quantum state of Bob's qubit is simply a Bayesian update that Alice performs on her state of knowledge about Bob's qubit, and no superluminal physical influences are needed. That the quantum state must be a state of knowledge is in fact the most natural lesson to draw from the steering phenomenon.

Unfortunately, the story is not so simple. Since Bell published his seminal [1964 paper](https://cds.cern.ch/record/111654/files/vol1p195-200_001.pdf), we now know that locality nevertheless fails even if quantum states are regarded as epistemic. The failure comes from the fact that a $\psi$-epistemic explanation still needs to account for the correlation of Alice's and Bob's measurement results (*always* anticorrelated, in the case of the singlet). Bell's theorem tells us that even if quantum states are regarded as epistemic, there can be no locally causal account of what quantum theory predicts. (If you are intrigued by this, stay tuned for my next blog post, which will be on Bell's theorem!) Nonetheless, the problem with locality is so obvious if the quantum state is ontic that we would not have needed the "big guns" of Bell's theorem. 

So what other aspects of quantum theory favor a $\psi$-epistemic interpretation over a $\psi$-ontic one? Turns out, it's most of quantum theory.


## Spekkens' toy model

What is your favorite quantum phenomenon? Entanglement? Teleportation? How about the weirdest, "quantumest" quantum phenomenon? Non-commutativity of measurements? Interference? The no-cloning theorem?

Let me now present to you a classical model that contains all of the above "quantum" phenomena. This model is astoundingly simple to describe and easy to undestand. One basically just needs two insights to have come up with it oneself: One, identify quantum states as states of knowledge about some underlying, real, *ontic states*. Two, impose a fundamental restriction on the *amount* of information that can be known. Do this with a discrete ontic state space, and you get [Spekkens' toy theory](https://arxiv.org/abs/quant-ph/0401052) [^cont].

[^cont]: This can be done for continuous ontic state spaces as well! Imposing the same epistemic restriction on a continuous phase space just yields a subtheory of continuous quantum mechanics, called Gaussian quantum mechanics.

A "toy bit", the smallest fundamental system in this model, can be in four possible ontic states. In other words, the *ontic state space* of a toy bit contains four ontic states. To describe this theory, it turns out that a graphical notation is most convenient. A toy bit is usually represented as a 2x2 box, and these are the four possible ontic states of a toy bit:

<center>
<img src="/images/psi-epi/ontic-states.jpeg" alt="ontic states" width="450"/>
</center>

The crucial ingredient of this theory is an *epistemic restriction*---a fundamental limit on the amount of knowledge that any agent can learn about a system. For a toy bit, it is posited that no agent can ever learn its ontic state exactly. Instead, the most they can know is to narrow it down to one of two possibilities. This gives rise to the notion of an *epistemic state*, a state of knowledge by some agent. An epistemic state is represented as a pattern of shaded boxes. For example, the picture on the left is a possible epistemic state, which in turn means that the ontic state is known to be one of the two possibilities on the right.

<center>
<img src="/images/psi-epi/epi-ontic-ex.jpeg" alt="example of epistemic/ontic" width="280"/>
</center>

The epistemic restriction means that there are only seven permitted epistemic states for a toy bit, as shown below. It is also possible to know nothing about a toy bit.

<center>
<img src="/images/psi-epi/all-epis.jpeg" alt="all epistemic states" width="400"/>
</center>

For this to be a complete theory, we need to know how a toy bit evolves, and how it behaves when undergoing measurements. We won't go into the details, but in order to preserve the epistemic restriction, it turns out that the only permitted transformations are *permutations* of ontic states. This means that we can only shuffle the four ontic states around. The shuffling in turn determines how the epistemic state is going to change. For example, below is a series of valid transformations, and their effects on an epistemic state. As we see with the second transformation, sometimes nontrivial transformations can leave the epistemic state unchanged.

<center>
<img src="/images/psi-epi/transf-ex.jpeg" alt="examples of transformations" width="550"/>
</center>

When a measurement is made on a toy bit, it also is not allowed to violate the epistemic restriction. This means that one is never allowed to ask which ontic state the toy bit is in. In fact, all allowed measurements are of the form, "which of the two regions is the ontic state in?" In other words, a measurement can only reveal one bit of information. This means also that the measurement outcome is decided *deterministically* by the ontic state that the toy bit is in. In the examples below, the measurement on the left gives outcome 1 deterministically, whereas the measurement on the right returns both outcomes with equal probability. To see why that is, recall that the epistemic state that we are given means that the ontic state is either in the top left (TL) or top right (TR). For both possibilities, when faced with the left measurement ("are you in the top or bottom half?"), the answer is 1. But for the right measurement ("are you in the left or right half?"), TL is going to give outcome 1, while TR gives outcome 2. Since it is not possible to know whether the ontic state was TL or TR to start with, what is observed given this initial epistemic state is that the measurement yields outcomes 1 and 2 with equal probability.

<center>
<img src="/images/psi-epi/meas-ex.jpeg" alt="examples of measurements" width="600"/>
</center>

To complete the description of measurements, one final step is needed. For the measurement on the right, note that the measurement result reveals the exact ontic state of the toy bit: TL for outcome 1, and TR for outcome 2. If nothing else happens, then we would have learned more than what is allowed by the epistemic restriction. To preserve the epistemic restriction, then, measurements will necessarily introduce a disturbance, and reshuffle the ontic states within each of the two regions. For the measurement on the right, this updates the epistemic state of the toy bit post-measurement, whereas the epistemic state is left unchanged for the measurement on the left.

<center>
<img src="/images/psi-epi/update.jpeg" alt="examples of post-measurement update" width="800"/>
</center>

This is essentially all one needs to define Spekkens' toy model. As it turns out, this is also all one needs to reproduce a large part of quantum theory. To make the connection with quantum theory, we just need to identify the allowed epistemic states on a toy bit with quantum states as the following:

<center>
<img src="/images/psi-epi/bloch.jpeg" alt="the Bloch sphere" width="500"/>
</center>

(In case you are not familiar with this picture, I'm drawing a [Bloch sphere](https://en.wikipedia.org/wiki/Bloch_sphere), which is a common way to visualize the state space of a qubit.)

Now, this toy theory is distinctively *not* the same as quantum theory. Roughly speaking, while quantum theory corresponds to the whole Bloch ball (i.e. surface + interior), the toy theory only corresponds to the octahedron formed by connecting the six labeled points on the Bloch sphere, called the *stabilizer subtheory* of quantum theory. [^stab] But the toy theory comes extremely close to quantum theory in the sense that it contains a long list of phenomena that feature in quantum theory that are normally considered nonclassical, while failing to reproduce only a few quantum phenomena. It essentially sorts quantum phenomenology into two buckets, by the following table:

[^stab]: This is technically a little bit wrong. It turns out that the theory of a toy bit is subtly different from the stabilizer subtheory of a qubit, but [Catani and Browne](https://iopscience.iop.org/article/10.1088/1367-2630/aa781c/pdf) has shown that the correspondence is exact for systems of all *odd* dimensions. This has to do with the fact that the qubit stabilizer subtheory is actually *contextual*. The toy theory is a noncontextual ontological model, so it cannot possibly reproduce all of the qubit stabilizer subtheory. Contextuality is also on the list of the topics I have planned for the next few blog posts, so stay tuned if you are interested in this point!

| appears in toy theory            | does not appear in toy theory          |
| :------------------------------: | :------------------------------------: |
| noncommutativity of measurements | Bell inequality violations             |
| collapse                         | noncontextuality inequality violations |
| coherent superposition           | computational speedup                  |
| no-cloning                       |   |
| interference                     |                                        |
| ambiguity of mixtures            |                                        |
| entanglement                     |                                        |
| steering                         |                                        |
| teleportation                    |                                        |
| and some more ...                |                                        |

For example, one can already see that the two example measurements discussed above don't commute: doing the left measurement first deterministically yields outcome 1, whereas if it is done after the right measurement, both outcomes are 50-50.
It is also clear that wavefunction collapse, which is a truly pretty problematic process if one thinks the wavefunction is ontic, is nothing more than the epistemic update upon learning new information after a measurement. I won't be going into the details of how any other phenomenon arises in the toy theory here in this post; if you are curious about a particular phenomenon on this list, you can find the discussion in Spekkens' original [paper](https://arxiv.org/abs/quant-ph/0401052).

There are many reasons why I find the toy theory so exciting. For one, it clarifies that there are at least two varieties of nonclassical phenomena: those that arise in a classical theory with an epistemic restriction, and those that cannot be reproduced in such a theory. This provides us with a simple method to assess the nonclassicality of any seemingly strange phenomenology: is it reproducible in the toy theory or not? In other words, we now have a principled answer to the question of "what is so weird about quantum mechanics?" 
Instead of resorting to personal wisdom such as the well-known [Feynman quote](https://www.feynmanlectures.caltech.edu/III_01.html) that interference phenomena "contain the _only_ mystery [of quantum mechanics]" [^interference], we now know that nonlocality and contextuality are the true mysteries of quantum mechanics. To crack open the strange case of quantum theory, we must focus our effort on understanding those.

[^interference]: Actually, one can understand all of the standard phenomenology on an interferometer, including the Elitzur-Vaidman bomb tester, using a framework akin to the toy model presented here. If you are interested in how that works, check out this [recent paper](https://arxiv.org/abs/2111.13727).

To me, Spekkens' toy model is also the single most suggestive piece of evidence about the nature of the quantum state. In the table above, one can't help but notice that the list on the left is very long, and the list on the right is very short. All but a handful of the phenomena we consider quantum are captured by Spekkens' toy model, which is just a classical theory of (restricted) information. It is natural to ask, why? Why is the toy theory so good at producing quantum phenomena and explaining them in terms of a theory of information? And the most logical answer for this is clear: it must be the case that quantum theory *is* also a theory of information. To me, the explanatory power provided by the toy theory is an unequivocal piece of evidence showing that the quantum state is a state of knowledge, rather than a state of reality.


## Concluding thoughts

To conclude, I would like to revisit the analogy with the decipherment of Egyptian hieroglyphs. I want to make the parallel completely explicit. In the case of hieroglyph decipherment, the incorrect assumption that the hieroglyphs are ideographic hindered progress for a millennium. The assumption was plausible, but was fundamentally not grounded in empirical evidence, and simply passed down by generations of scholars without anyone thinking to question it. Even after it was found that the hieroglyphs were phonetic when appearing in cartouches, Champollion was slow to generalize this insight to the rest of the script, because he was held back by the false premise.

Could this be what's going on with the interpretation of quantum mechanics, too? The dominant view passed along by our textbooks and existing interpretations is that the quantum state is ontic, a state of reality. This is certainly plausible, but not only is there no good evidence supporting it, it leads to problematic conflict with locality quite readily (at least more readily than with the $\psi$-epistemic view). Spekkens' toy model shows that at least in the context of a subtheory of quantum theory, quantum states behave as if they are states of knowledge. If the parallel with the hieroglyph story continues to hold, then, maybe what will lead to an eventual breakthrough in the interpretation of quantum theory is to embrace the fact that the quantum state is a state of knowledge in general.

All this to say, it is not that I think the $\psi$-epistemic position must be 100% correct. The bottom line is, it is simply very surprising how essentially all interpretational effort has been put into the $\psi$-ontic basket, whereas there is very good evidence that the $\psi$-epistemic approach is also worth investigating, if not more so. Given the evidence on the table, especially Spekkens' toy model, I also think that now any satisfactory interpretation of quantum theory, especially ones that take the $\psi$-ontic approach, must pass the bar of explaining why the quantum state behaves so much like a state of knowledge. 

Finally, let me end by saying that we are probably pretty far from the end of the story, even if you are sympathetic to the $\psi$-epistemic view. We are not where Champollion was in July 1822. If quantum states are states of knowledge, the problem is that we have no idea what the knowledge is *about*. Restricted knowledge about four ontic states gave us something very close to the quantum theory of a qubit, but we *know* that we can't get much closer with simple modifications to Spekkens' toy model, because of two classes of no-go theorems---Bell-like theorems and contextuality no-go theorems. At the end of the day, Spekkens' toy model is a local, noncontextual ontological model, and we know that we must go beyond the assumptions of such a model in order to have any hopes of understanding all the mysteries of quantum theory. 

 
---

Much of this post is based on Rob Spekkens’ excellent public lecture at the Perimeter Institute, [The riddle of the quantum sphinx](https://pirsa.org/18020008). Rob is an excellent speaker---if you are someone that enjoys lectures, feel free to check it out!
